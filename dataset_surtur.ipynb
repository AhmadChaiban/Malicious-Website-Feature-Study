{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Surtur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob as globlin\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urlextract import URLExtract\n",
    "import statistics\n",
    "import os\n",
    "import csv\n",
    "import onemillion\n",
    "import socket\n",
    "\n",
    "import io\n",
    "from imageio import imread\n",
    "\n",
    "import geoip2.database\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import signal\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import plot, iplot\n",
    "import plotly.express as px\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "@contextmanager\n",
    "def timeout(time):\n",
    "    # Register a function to raise a TimeoutError on the signal.\n",
    "    signal.signal(signal.SIGALRM, raise_timeout)\n",
    "    # Schedule the signal to be sent after ``time``.\n",
    "    signal.alarm(time)\n",
    "\n",
    "    try:\n",
    "        yield\n",
    "    except TimeoutError:\n",
    "        return 'timeout error'\n",
    "    finally:\n",
    "        # Unregister the signal so it won't be triggered\n",
    "        # if the timeout is not reached.\n",
    "        signal.signal(signal.SIGALRM, signal.SIG_IGN)\n",
    "\n",
    "\n",
    "def raise_timeout(signum, frame):\n",
    "    raise TimeoutError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(main_path):\n",
    "    \"\"\"reading the benign samples\"\"\"\n",
    "    dataframe_array = []\n",
    "    benign_data_paths = globlin(main_path)\n",
    "    for path in benign_data_paths:\n",
    "        dataframe_array.append(pd.read_csv(path))\n",
    "        #print(pd.read_csv(path).columns)\n",
    "    return pd.concat(dataframe_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur = read_data('./data_construction/4 - final_data/*.csv').drop(columns=['Unnamed: 0.1'])\n",
    "df_mal_sup = read_data('./data_construction/supp_malicious_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mal_sup = df_mal_sup.drop(columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur = dataset_surtur.drop(columns=['status', 'https.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mal_sup.columns = ['url', 'has_IP_in_url', 'number_subdomains', 'hostname',\n",
    "       'length_hostname', 'ratio_digits_url', 'having_@_in_url',\n",
    "       'ratio_digits_hostname', 'number_underscores', 'tld', 'url_len',\n",
    "       'https', 'who_is', 'content', 'label']\n",
    "\n",
    "df_mal_sup.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur = pd.concat([dataset_surtur, df_mal_sup], axis=0, sort=False).drop_duplicates()\n",
    "dataset_surtur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting JS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_js(content, supp=False):\n",
    "    tags_of_interest = [\n",
    "        '<script type=\"text/javascript\">', \n",
    "        '<script>'\n",
    "    ]\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    js = soup.find_all('script')\n",
    "    complete_js = ''\n",
    "    for tag in js:\n",
    "        for tag_int in tags_of_interest:\n",
    "            if tag_int in str(tag):\n",
    "                complete_js += str(tag).replace(tag_int, '').replace(\n",
    "                    '</script>', '')\n",
    "    return complete_js.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['js'] = dataset_surtur['content'].progress_apply(lambda content: get_js(str(content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JS Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['js_len'] = dataset_surtur['js'].progress_apply(lambda js: len(js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_string_thing = dataset_surtur[dataset_surtur['js_len']==0].iloc[1]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Script tag references in html page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def script_references(js):\n",
    "    return js.count('<script')/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['js_ref'] = dataset_surtur['content'].progress_apply(\n",
    "    lambda content: script_references(str(content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting array lengths from JS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_array_length(js):\n",
    "    array_lengths = re.findall('\\(([^\\)]+)\\)', js)\n",
    "    if array_lengths == []:\n",
    "        return 0\n",
    "    return max([len(i) for i in array_lengths])\n",
    "\n",
    "def get_avg_array_length(js):\n",
    "    array_lengths = re.findall('\\(([^\\)]+)\\)', js)\n",
    "    if array_lengths == []:\n",
    "        return 0\n",
    "    return statistics.mean([len(i) for i in array_lengths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['js_array_len_avg'] = dataset_surtur['js'].progress_apply(\n",
    "    lambda js: get_avg_array_length(str(js)))\n",
    "dataset_surtur['js_array_len_max'] = dataset_surtur['js'].progress_apply(\n",
    "    lambda js: get_max_array_length(str(js)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['content_len'] = dataset_surtur['content'].progress_apply(\n",
    "    lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['js'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_func_calls(js):\n",
    "    full_paren = len(re.findall(\"\\(([^\\)]+)\\)\", js))\n",
    "    empty_paren = len(js.split('()'))\n",
    "    return full_paren + empty_paren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['num_js_func_calls'] = dataset_surtur['js'].progress_apply(\n",
    "    lambda x: get_func_calls(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suspicious Function Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sus_js_function_count(js):\n",
    "    function_list = [\n",
    "        'setcookie', 'getcookie', 'createxmlhttprequest', 'unescape',\n",
    "        'document.write', 'element.appendchild', 'dateobject.togmtstring',\n",
    "        'new activexobject', 'document.createelement', 'getappname',\n",
    "        'getuseragent', 'window.setinterval', 'window.settimeout',\n",
    "        'location.assign', 'location.replace', 'eval()', 'string.indexof',\n",
    "        'string.fromcharcode', 'charat', 'split',\n",
    "        'string.charcodeat', 'document.writeln', 'document.appendchild',\n",
    "        'innerhtml', 'insertAdjacentHTML', 'outerhtml', \n",
    "    ]\n",
    "\n",
    "    split_js = js.replace('\\n',' ').split(' ')\n",
    "    counter = 0\n",
    "    for element in split_js:\n",
    "        if any(m_function in element.lower() for m_function in function_list):\n",
    "            counter += 1\n",
    "\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['malicious_func_count'] = dataset_surtur['js'].progress_apply(\n",
    "    lambda js: get_sus_js_function_count(str(js)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get total and external URL count in content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_urls(string, ext_count):\n",
    "#     # with timeout(1):\n",
    "#     regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "#     url = re.findall(regex, string)\n",
    "#     if ext_count:\n",
    "#         return len(set(url))\n",
    "#     return len(url)\n",
    "\n",
    "\n",
    "# # Test Code\n",
    "# string = 'My Profile: https://auth.geeksforgeeks.org/user/Chinmoy%20Lenka/articles in the portal of http://www.geeksforgeeks.org/'\n",
    "# print(\"Urls: \", find_urls(string, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_urls(string, ext_count):\n",
    "    try:\n",
    "        extractor = URLExtract()\n",
    "        urls = extractor.find_urls(string)\n",
    "        if ext_count: \n",
    "            return len(set(urls))\n",
    "        return len(urls)\n",
    "    except:\n",
    "        return 10000\n",
    "\n",
    "string_ex = 'My Profile: https://auth.geeksforgeeks.org/user/Chinmoy%20Lenka/articles in the portal of http://www.geeksforgeeks.org/'\n",
    "    \n",
    "print(find_urls(string_ex, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['total_url_count'] = dataset_surtur['content'].progress_apply(\n",
    "    lambda js: find_urls(str(js), False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['ext_url_count'] = dataset_surtur['content'].progress_apply(\n",
    "    lambda js: find_urls(str(js), True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Lexical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['num_semicolons'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count(';'))\n",
    "dataset_surtur['num_zeros'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('0'))\n",
    "dataset_surtur['num_spaces'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('%20'))\n",
    "dataset_surtur['num_hyphens'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('-'))\n",
    "dataset_surtur['num_@s'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('@'))\n",
    "dataset_surtur['num_queries'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('?'))\n",
    "dataset_surtur['num_ampersands'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('&'))\n",
    "dataset_surtur['num_equals'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('='))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safe Browsing API Judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./safebrowsingkey.txt') as f:\n",
    "    api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "key = 'your key here'\n",
    "URL = \"https://sb-ssl.google.com/safebrowsing/api/lookup?client=api&apikey={key}&appver=1.0&pver=3.0&url={url}\"\n",
    "\n",
    "\n",
    "def is_safe(url):\n",
    "    try:\n",
    "        response = requests.get(URL.format(key=api_key, url=url))\n",
    "        return response.text != 'malware'\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "\n",
    "print(is_safe('http://addonrock.ru/Debugger.js/'))  # prints False\n",
    "print(is_safe('http://google.com'))  # prints True\n",
    "\n",
    "\n",
    "dataset_surtur['google_is_safe'] = dataset_surtur['url'].progress_apply(lambda url: is_safe(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Domain names and their lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['domain'] = dataset_surtur['hostname'].progress_apply(\n",
    "    lambda hostname: '.'.join(str(hostname).split('.')[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['domain_len'] = dataset_surtur['domain'].progress_apply(lambda domain: len(domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presence in Alexa domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'domain_lists': [\n",
    "        {\n",
    "            'name': \"alexa\",\n",
    "            'output_file_path': \"alexa.csv\",\n",
    "            'url': \"http://s3.amazonaws.com/alexa-static/top-1m.csv.zip\"\n",
    "        }, {\n",
    "            'name': \"cisco umbrella\",\n",
    "            'output_file_path': \"cisco.csv\",\n",
    "            'url': \"http://s3-us-west-1.amazonaws.com/umbrella-static/\" +\n",
    "                   \"top-1m.csv.zip\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Cache our top 1 million known domains\n",
    "DEFAULT_CACHE_LOCATION = '~/.onemillion'\n",
    "cache_location = os.path.expanduser(DEFAULT_CACHE_LOCATION)\n",
    "\n",
    "# O(n) to read Csv file rows into set \n",
    "def read_onemillion_data():\n",
    "    \"\"\"Check if the given domain is in a top on million list.\"\"\"\n",
    "    # TODO: parse the registered domain out of the domain parameter\n",
    "\n",
    "    # keep track of the highest (nearest to 1) rank for the given domain\n",
    "    highest_rank = None\n",
    "\n",
    "    # see if the given domain is in the up-to-date domain lists\n",
    "    domains = set()\n",
    "    for domain_list in CONFIG['domain_lists']:\n",
    "        # open the domain list as a CSV\n",
    "        with open(os.path.join(cache_location, domain_list['output_file_path']), 'r') as domain_csv:\n",
    "            domain_reader = csv.reader(domain_csv)\n",
    "            for row in domain_reader:\n",
    "                domains.add(row[1])\n",
    "    return domains\n",
    "\n",
    "\n",
    "domains_onemillion = read_onemillion_data()\n",
    "\n",
    "# O(1) Function Run time\n",
    "def domain_checker(domain):\n",
    "    domain = domain.lower()\n",
    "    if domain in domains:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "o = onemillion.OneMillion()\n",
    "\n",
    "def check_if_in_onemillion(domain):\n",
    "    if domain in domains_onemillion:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "dataset_surtur['is_in_alexa'] = dataset_surtur['domain'].progress_apply(\n",
    "    lambda domain: check_if_in_onemillion(domain))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur.iloc[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur.iloc[2]['url'].split('/')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socket.gethostbyname(dataset_surtur['url'].iloc[28].split('/')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['url'].iloc[27].split('/')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ip_url(url):\n",
    "    try:\n",
    "        domain = url.split('/')[2]\n",
    "        return socket.gethostbyname(domain)\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "dataset_surtur['ip_address'] = dataset_surtur['url'].progress_apply(\n",
    "    lambda url: get_ip_url(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['ip_address'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_surtur[dataset_surtur['ip_address'] == 'unknown'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get location of each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = geoip2.database.Reader('./GeoLite2-Country.mmdb')\n",
    "\n",
    "def get_location(ip_add):\n",
    "    try:\n",
    "        if ip_add == 'unknown':\n",
    "            return 'unknown'\n",
    "        response = reader.country(ip_add)\n",
    "        return response.country.name\n",
    "    except Exception as msg:\n",
    "        return 'unknown'\n",
    "\n",
    "dataset_surtur['location'] = dataset_surtur['ip_address'].progress_apply(\n",
    "    lambda ip_add: get_location(ip_add))\n",
    "\n",
    "reader.close()\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_adjustor(dataset_column):\n",
    "    unique_values = dataset_column.unique()\n",
    "    return dataset_column.progress_apply(lambda x: np.where(unique_values == x)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur = dataset_surtur.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['who_is'] = column_adjustor(dataset_surtur['who_is'])\n",
    "dataset_surtur['https'] = column_adjustor(dataset_surtur['https'])\n",
    "dataset_surtur['tld'] = column_adjustor(dataset_surtur['tld'])\n",
    "dataset_surtur['google_is_safe'] = column_adjustor(dataset_surtur['google_is_safe'])\n",
    "dataset_surtur['location'] = column_adjustor(dataset_surtur['location'])\n",
    "\n",
    "\n",
    "dataset_surtur['label'] = dataset_surtur['label'].progress_apply(\n",
    "    lambda label: 1 if 'bad' in label else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_surtur.to_csv('./dataset_surtur.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_surtur = pd.read_csv('./dataset_surtur.csv')\n",
    "dataset_surtur.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surtur_alpha = pd.read_csv('./dataset_surtur_alpha.csv')\n",
    "df_surtur_alpha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_surtur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "# import io\n",
    "# import cv2\n",
    "# from imageio import imread\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # reconstruct image as an numpy array\n",
    "# img = imread(io.BytesIO(base64.b64decode(img_string)))\n",
    "\n",
    "# # show image\n",
    "# plt.figure()\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "# # finally convert RGB image to BGR for opencv\n",
    "# # and save result\n",
    "# cv2_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_for_org_index = globlin('./img_extract/dataset_surtur_images_original_index_insert/*.png')\n",
    "imgs_for_mal_separate = globlin('./img_extract/dataset_surt_images_malicious/*.png')\n",
    "imgs_for_ben_separate = globlin('./img_extract/dataset_surtur_images_unique_index (when isolating benign)/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs = np.zeros(len(df_surtur_alpha)).astype('str')\n",
    "\n",
    "pbar = tqdm(total=len(imgs_for_org_index) + len(imgs_for_ben_separate) + len(imgs_for_mal_separate)) \n",
    "\n",
    "def get_saved_index(path):\n",
    "    return int(path.split('/')[-1].replace('_0.png', '').replace('_1.png', ''))\n",
    "\n",
    "def load_as_base64(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img_string = base64.b64encode(f.read()).decode()\n",
    "    return img_string\n",
    "\n",
    "### INSERTING IMAGES WITH NO ALTERED INDEXES\n",
    "for path in imgs_for_org_index:\n",
    "    img_index = get_saved_index(path)\n",
    "    base64_image = load_as_base64(path)\n",
    "    df_imgs[img_index] = base64_image\n",
    "    \n",
    "    pbar.update(1)\n",
    "    \n",
    "df_surtur_alpha['image'] = df_imgs\n",
    "\n",
    "df_surtur_alpha_malicious = df_surtur_alpha[df_surtur_alpha['label'] == 1].reset_index()\n",
    "df_surtur_alpha_benign = df_surtur_alpha[df_surtur_alpha['label'] == 0].reset_index()\n",
    "\n",
    "df_imgs_mal = np.array(df_surtur_alpha_malicious['image'])\n",
    "df_imgs_ben = np.array(df_surtur_alpha_benign['image'])\n",
    "\n",
    "for path in imgs_for_mal_separate:\n",
    "    img_index = get_saved_index(path)\n",
    "    base64_image = load_as_base64(path)\n",
    "    df_imgs_mal[img_index] = base64_image\n",
    "    pbar.update(1)\n",
    "    \n",
    "for path in imgs_for_ben_separate:\n",
    "    img_index = get_saved_index(path)\n",
    "    base64_image = load_as_base64(path)\n",
    "    df_imgs_ben[img_index] = base64_image\n",
    "    pbar.update(1)\n",
    "    \n",
    "df_surtur_alpha_malicious['image'] = df_imgs_mal\n",
    "df_surtur_alpha_benign['image'] = df_imgs_ben\n",
    "\n",
    "\n",
    "df_surtur_alpha = pd.concat([df_surtur_alpha_malicious, df_surtur_alpha_benign], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_surtur_alpha[df_surtur_alpha['image']=='0.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surtur_alpha_adjusted = df_surtur_alpha[df_surtur_alpha['url'].isin(\n",
    "    dataset_surtur['url'].values.tolist())].sort_values('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur = dataset_surtur.sort_values('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surtur_alpha_adjusted['google_is_safe'] = dataset_surtur['google_is_safe'].values.tolist()\n",
    "df_surtur_alpha_adjusted['ip_address'] = dataset_surtur['ip_address'].values.tolist()\n",
    "df_surtur_alpha_adjusted['location'] = dataset_surtur['location'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_surtur_alpha_adjusted.to_csv('./dataset_surtur_2_w_images.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>has_IP_in_url</th>\n",
       "      <th>having_@_in_url</th>\n",
       "      <th>hostname</th>\n",
       "      <th>https</th>\n",
       "      <th>label</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>number_subdomains</th>\n",
       "      <th>number_underscores</th>\n",
       "      <th>ratio_digits_hostname</th>\n",
       "      <th>ratio_digits_url</th>\n",
       "      <th>tld</th>\n",
       "      <th>url</th>\n",
       "      <th>url_len</th>\n",
       "      <th>who_is</th>\n",
       "      <th>js</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_ref</th>\n",
       "      <th>js_array_len_avg</th>\n",
       "      <th>js_array_len_max</th>\n",
       "      <th>content_len</th>\n",
       "      <th>num_js_func_calls</th>\n",
       "      <th>malicious_func_count</th>\n",
       "      <th>total_url_count</th>\n",
       "      <th>ext_url_count</th>\n",
       "      <th>num_semicolons</th>\n",
       "      <th>num_zeros</th>\n",
       "      <th>num_spaces</th>\n",
       "      <th>num_hyphens</th>\n",
       "      <th>num_@s</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>num_ampersands</th>\n",
       "      <th>num_equals</th>\n",
       "      <th>domain</th>\n",
       "      <th>domain_len</th>\n",
       "      <th>image</th>\n",
       "      <th>google_is_safe</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>49707</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;meta content=\"no-cache\" http-equi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00.124.324.77.00.opteamevent.hu</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>42</td>\n",
       "      <td>http://00.124.324.77.00.opteamevent.hu/</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b''</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>opteamevent.hu</td>\n",
       "      <td>14</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAABVYAAAKZCAYAAABTIHD9AA...</td>\n",
       "      <td>0</td>\n",
       "      <td>91.82.220.51</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>48436</td>\n",
       "      <td>\u0013�MQTH1TDa1��fl�hF1bVOF\u0004ESLCnBbRI9MRTH1PDa1SP...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00005ik.rcomhost.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0</td>\n",
       "      <td>http://00005ik.rcomhost.com/7fg3g</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b''</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rcomhost.com</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>206.188.193.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>97761</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html data-adblockkey=\"MFwwDQ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>000098.ihostfull.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0</td>\n",
       "      <td>http://000098.ihostfull.com/</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'g_pb=(function(){var\\nDT=document,azx=locati...</td>\n",
       "      <td>3301</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.245902</td>\n",
       "      <td>61</td>\n",
       "      <td>4092</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ihostfull.com</td>\n",
       "      <td>13</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAABUUAAAKuCAYAAACGxn0DAA...</td>\n",
       "      <td>0</td>\n",
       "      <td>199.59.242.153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>103181</td>\n",
       "      <td>&lt;html&gt;\\n&lt;head&gt;\\n&lt;meta content=\"noarchive\" name...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>000p6vl.wcomhost.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>http://000p6vl.wcomhost.com/Ameli-Assurance/re...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b''</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wcomhost.com</td>\n",
       "      <td>12</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAABVYAAAA7CAYAAACQa9ExAA...</td>\n",
       "      <td>0</td>\n",
       "      <td>208.91.197.27</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>47694</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;meta content=\"no-cache\" http-equi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>001.002.003.23.opteamevent.hu</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>42</td>\n",
       "      <td>http://001.002.003.23.opteamevent.hu/</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b''</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>opteamevent.hu</td>\n",
       "      <td>14</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAABVYAAAKZCAYAAABTIHD9AA...</td>\n",
       "      <td>0</td>\n",
       "      <td>91.82.220.51</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                            content  has_IP_in_url  \\\n",
       "0   49707  <html><head><meta content=\"no-cache\" http-equi...            0.0   \n",
       "1   48436  \u001f\u0013�MQTH1TDa1��fl�hF1bVOF\u0004ESLCnBbRI9MRTH1PDa1SP...            0.0   \n",
       "2   97761  <!DOCTYPE html>\\n<html data-adblockkey=\"MFwwDQ...            0.0   \n",
       "3  103181  <html>\\n<head>\\n<meta content=\"noarchive\" name...            0.0   \n",
       "4   47694  <html><head><meta content=\"no-cache\" http-equi...            0.0   \n",
       "\n",
       "   having_@_in_url                         hostname  https  label  \\\n",
       "0              0.0  00.124.324.77.00.opteamevent.hu      0      1   \n",
       "1              0.0             00005ik.rcomhost.com      0      1   \n",
       "2              0.0             000098.ihostfull.com      0      1   \n",
       "3              0.0             000p6vl.wcomhost.com      0      1   \n",
       "4              0.0    001.002.003.23.opteamevent.hu      0      1   \n",
       "\n",
       "   length_hostname  number_subdomains  number_underscores  \\\n",
       "0             31.0                6.0                 0.0   \n",
       "1             20.0                1.0                 0.0   \n",
       "2             20.0                1.0                 0.0   \n",
       "3             20.0                1.0                 0.0   \n",
       "4             29.0                5.0                 0.0   \n",
       "\n",
       "   ratio_digits_hostname  ratio_digits_url  tld  \\\n",
       "0               0.387097          0.307692   42   \n",
       "1               0.250000          0.212121    0   \n",
       "2               0.300000          0.214286    0   \n",
       "3               0.200000          0.062500    0   \n",
       "4               0.379310          0.297297   42   \n",
       "\n",
       "                                                 url  url_len  who_is  \\\n",
       "0            http://00.124.324.77.00.opteamevent.hu/     39.0       0   \n",
       "1                  http://00005ik.rcomhost.com/7fg3g     33.0       0   \n",
       "2                       http://000098.ihostfull.com/     28.0       0   \n",
       "3  http://000p6vl.wcomhost.com/Ameli-Assurance/re...     64.0       0   \n",
       "4              http://001.002.003.23.opteamevent.hu/     37.0       0   \n",
       "\n",
       "                                                  js  js_len  js_ref  \\\n",
       "0                                                b''       0     0.0   \n",
       "1                                                b''       0     0.0   \n",
       "2  b'g_pb=(function(){var\\nDT=document,azx=locati...    3301     0.5   \n",
       "3                                                b''       0     0.0   \n",
       "4                                                b''       0     0.0   \n",
       "\n",
       "   js_array_len_avg  js_array_len_max  content_len  num_js_func_calls  \\\n",
       "0          0.000000                 0          165                  1   \n",
       "1          0.000000                 0           93                  1   \n",
       "2         22.245902                61         4092                 89   \n",
       "3          0.000000                 0          262                  1   \n",
       "4          0.000000                 0          165                  1   \n",
       "\n",
       "   malicious_func_count  total_url_count  ext_url_count  num_semicolons  \\\n",
       "0                     0                0              0               0   \n",
       "1                     0                0              0               0   \n",
       "2                     2                1              1               0   \n",
       "3                     0                0              0               0   \n",
       "4                     0                0              0               0   \n",
       "\n",
       "   num_zeros  num_spaces  num_hyphens  num_@s  num_queries  num_ampersands  \\\n",
       "0          4           0            0       0            0               0   \n",
       "1          4           0            0       0            0               0   \n",
       "2          4           0            0       0            0               0   \n",
       "3          3           0            1       0            0               0   \n",
       "4          6           0            0       0            0               0   \n",
       "\n",
       "   num_equals          domain  domain_len  \\\n",
       "0           0  opteamevent.hu          14   \n",
       "1           0    rcomhost.com          12   \n",
       "2           0   ihostfull.com          13   \n",
       "3           0    wcomhost.com          12   \n",
       "4           0  opteamevent.hu          14   \n",
       "\n",
       "                                               image  google_is_safe  \\\n",
       "0  iVBORw0KGgoAAAANSUhEUgAABVYAAAKZCAYAAABTIHD9AA...               0   \n",
       "1                                                0.0               0   \n",
       "2  iVBORw0KGgoAAAANSUhEUgAABUUAAAKuCAYAAACGxn0DAA...               0   \n",
       "3  iVBORw0KGgoAAAANSUhEUgAABVYAAAA7CAYAAACQa9ExAA...               0   \n",
       "4  iVBORw0KGgoAAAANSUhEUgAABVYAAAKZCAYAAABTIHD9AA...               0   \n",
       "\n",
       "       ip_address  location  \n",
       "0    91.82.220.51        35  \n",
       "1  206.188.193.86         0  \n",
       "2  199.59.242.153         0  \n",
       "3   208.91.197.27        57  \n",
       "4    91.82.220.51        35  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_surtur = pd.read_csv('./dataset_surtur_2_w_images.csv')\n",
    "dataset_surtur.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/105485 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105485/105485 [1:48:52<00:00, 16.59it/s] "
     ]
    }
   ],
   "source": [
    "def read_image(base64_image):\n",
    "    img = imread(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    return cv2.resize(cv2.cvtColor(img, cv2.COLOR_RGB2BGR), (512, 512))\n",
    "\n",
    "pbar = tqdm(total=len(dataset_surtur))\n",
    "\n",
    "\n",
    "model = tf.keras.applications.MobileNetV2(include_top=False, \n",
    "                                          weights='imagenet', \n",
    "                                          input_shape=(512, 512, 3))\n",
    "\n",
    "\n",
    "images = dataset_surtur['image'].values.tolist()\n",
    "\n",
    "image_features = []\n",
    "for base64_image in images:\n",
    "    try:\n",
    "        if base64_image == '0.0':\n",
    "            image_features.append(np.zeros((1, 16, 16, 1280)))\n",
    "        else:\n",
    "            cv2_image = read_image(base64_image).reshape([1, 512, 512, 3])\n",
    "            image_features.append(model.predict(cv2_image))\n",
    "    except:\n",
    "        image_features.append(np.zeros((1, 16, 16, 1280)))\n",
    "    pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 105485/105485 [1:49:03<00:00, 16.59it/s]"
     ]
    }
   ],
   "source": [
    "image_features_2d = pd.DataFrame(np.array(image_features).reshape(len(image_features), 1280*16*16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feat_new = SelectKBest(chi2, k=20).fit_transform(image_features, dataset_surtur['label'])\n",
    "image_feat_new = pd.DataFrame(image_feat_new)\n",
    "\n",
    "feat_array = []\n",
    "for i in tqdm(range(len(image_feat_new.columns))):\n",
    "     feat_array.append(f'image_mobnet_{i}')\n",
    "        \n",
    "image_feat_new.columns = feat_array\n",
    "image_feat_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur_mbnet_feat = pd.concat([dataset_surtur, content_feat_new], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur_mbnet_feat.to_csv('./dataset_surtur_image_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_to_change = dataset_surtur['content']\n",
    "labels_for_content = dataset_surtur['label']\n",
    "\n",
    "maxlen = 512\n",
    "\n",
    "tokenizer = Tokenizer(num_words=40000)\n",
    "tokenizer.fit_on_texts(content_to_change)\n",
    "content_set = tokenizer.texts_to_sequences(content_to_change)\n",
    "content_set = pad_sequences(content_set, padding='post', maxlen=maxlen)\n",
    "# print(len(content_set))\n",
    "\n",
    "# content_set = np.array(content_set).reshape([len(content_to_change), 75, 75, 3])\n",
    "\n",
    "# print(np.array(content_set).reshape([11721 100 3 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_full_set = []\n",
    "# for i in tqdm(range(len(content_set))):\n",
    "#     x = [tf.convert_to_tensor(content_set[i])]\n",
    "#     x.append(labels_for_content[i])\n",
    "#     content_full_set.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(dataset_surtur['content_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_surtur['content'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dataset_surtur['url_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_surtur['url'].iloc[103161])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['url_len'].nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['content_len'].nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, pipeline, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', \n",
    "                                    output_hidden_states=True)\n",
    "                                   # hidden_size=)\n",
    "\n",
    "model = AutoModel.from_pretrained('bert-base-uncased', config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased',\n",
    "                                          add_special_tokens=True,    \n",
    "                                          truncation=True, \n",
    "                                          padding=True, \n",
    "                                          return_attention_mask=True, \n",
    "                                          return_tensors = \"pt\")\n",
    "\n",
    "nlp = pipeline('feature-extraction', model=model, tokenizer=tokenizer)\n",
    "\n",
    "url_features = tqdm(nlp(dataset_surtur['content'].iloc[33109]), total=len(dataset_surtur))\n",
    "print(url_features)\n",
    "features = np.squeeze(url_features)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.MobileNetV2(include_top=False, \n",
    "                                          weights='imagenet', \n",
    "                                          input_shape=(75, 75, 3))\n",
    "\n",
    "content_features = []\n",
    "\n",
    "for index, content in tqdm(enumerate(content_set), total=len(content_set)):\n",
    "    content = content.reshape([1, 75, 75, 3])\n",
    "    content_features.append(model.predict(content))\n",
    "\n",
    "# pred_images = predictions.reshape(images_dataset.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(content_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_features = pd.DataFrame(np.array(content_features).reshape(len(content_features), 1280*3*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_features.to_csv('content_features_surtur_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_features = pd.read_csv('content_features_surtur_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Square selection of extracted nlp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_feat_new = SelectKBest(chi2, k=20).fit_transform(content_features, dataset_surtur['label'])\n",
    "content_feat_new = pd.DataFrame(content_feat_new)\n",
    "\n",
    "feat_array = []\n",
    "for i in tqdm(range(len(content_feat_new.columns))):\n",
    "     feat_array.append(f'content_mobnet_{i}')\n",
    "        \n",
    "content_feat_new.columns = feat_array\n",
    "content_feat_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur_mbnet_feat = pd.concat([dataset_surtur, content_feat_new], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_change = dataset_surtur['url']\n",
    "labels_for_url = dataset_surtur['label']\n",
    "\n",
    "maxlen = 32*32*3\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(url_to_change)\n",
    "url_set = tokenizer.texts_to_sequences(url_to_change)\n",
    "url_set = pad_sequences(url_set, padding='post', maxlen=maxlen)\n",
    "# print(len(url_set))\n",
    "\n",
    "url_set = np.array(url_set).reshape([len(url_to_change), 32, 32, 3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_full_set = []\n",
    "for i in tqdm(range(len(url_set))):\n",
    "    x = [tf.convert_to_tensor(url_set[i])]\n",
    "    x.append(labels_for_url[i])\n",
    "    url_full_set.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.MobileNetV2(include_top=False, \n",
    "                                          weights='imagenet', \n",
    "                                          input_shape=(32, 32, 3))\n",
    "\n",
    "url_features = []\n",
    "\n",
    "for index, url in tqdm(enumerate(url_set), total=len(url_set)):\n",
    "    url = url.reshape([1, 32, 32, 3])\n",
    "    url_features.append(model.predict(url))\n",
    "\n",
    "# pred_images = predictions.reshape(images_dataset.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(url_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_features = pd.DataFrame(np.array(url_features).reshape(len(url_features), 1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_features.to_csv('url_features_surtur.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_features = pd.read_csv('url_features_surtur.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_feat_new = SelectKBest(chi2, k=5).fit_transform(url_features, dataset_surtur['label'])\n",
    "url_feat_new = pd.DataFrame(url_feat_new)\n",
    "\n",
    "feat_array = []\n",
    "for i in tqdm(range(len(url_feat_new.columns))):\n",
    "     feat_array.append(f'url_mobnet_{i}')\n",
    "        \n",
    "url_feat_new.columns = feat_array\n",
    "url_feat_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur_ext_feat = pd.concat([dataset_surtur_mbnet_feat, url_feat_new], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = dataset_surtur.drop(\n",
    "    columns=['url', 'content', 'hostname', 'js', 'google_is_safe', 'label']).columns[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = dataset_surtur_ext_feat.drop(\n",
    "    columns=['url', 'content', 'hostname', 'js', 'label', \n",
    "             'domain', 'google_is_safe','ip_address']).columns[::-1]\n",
    "# 'total_url_count', 'ext_url_count'\n",
    "\n",
    "x = dataset_surtur_ext_feat[dataset_surtur_ext_feat['label'] == 1][to_keep].copy()  #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x.values)\n",
    "df_to_plot_malicious = pd.DataFrame(x_scaled)\n",
    "df_to_plot_malicious.columns = dataset_surtur_ext_feat[to_keep].columns\n",
    "df_to_plot_malicious['label'] = 1.0\n",
    "\n",
    "x = dataset_surtur_ext_feat[dataset_surtur_ext_feat['label'] == 0][to_keep].copy()  #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x.values)\n",
    "df_to_plot_benign = pd.DataFrame(x_scaled)\n",
    "df_to_plot_benign.columns = dataset_surtur_ext_feat[to_keep].columns\n",
    "df_to_plot_benign['label'] = 0.0\n",
    "\n",
    "normalized_per_class_dataset = pd.concat([df_to_plot_malicious, df_to_plot_benign], axis=0)\n",
    "\n",
    "x = dataset_surtur_ext_feat[to_keep].copy()  #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x.values)\n",
    "dataset_surt_norm = pd.DataFrame(x_scaled)\n",
    "dataset_surt_norm.columns = dataset_surtur_ext_feat[to_keep].columns\n",
    "dataset_surt_norm['label'] = dataset_surtur_ext_feat['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "\n",
    "# num_df_surt = dataset_surt_norm.select_dtypes(include=[\"number\"])\n",
    "# cat_df_surt = dataset_surt_norm.select_dtypes(exclude=[\"number\"])\n",
    "\n",
    "# # idx = np.all(stats.zscore(num_df_surt) < 3, axis=1)\n",
    "\n",
    "# # dataset_surt_norm_cleaned = pd.concat([num_df_surt.loc[idx], \n",
    "# #                                    cat_df_surt.loc[idx]], axis=1)\n",
    "\n",
    "# Q1 = num_df_surt.quantile(0.10)\n",
    "# Q3 = num_df_surt.quantile(0.80)\n",
    "# IQR = Q3 - Q1\n",
    "# idx = ~((num_df_surt < (Q1 - 1.5 * IQR)) | (num_df_surt > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "# dataset_surt_norm_cleaned = pd.concat([num_df_surt.loc[idx], \n",
    "#                                     cat_df_surt.loc[idx]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataset_surt_norm_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes_to_drop = dataset_surtur.nlargest(15000, 'js_len')['js_len'].index\n",
    "# dataset_surtur = dataset_surtur.drop(indexes_to_drop, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# features = dataset_surtur.drop(columns=['url', 'content', 'hostname', 'js', \n",
    "#                                         'label']).columns[::-1] #, 'total_url_count', 'ext_url_count']).columns[::-1]\n",
    "# df_to_plot = dataset_surtur\n",
    "\n",
    "# n_bins = 40\n",
    "\n",
    "# fig, axs = plt.subplots(5, 6, figsize=(20,20))\n",
    "\n",
    "# # We can set the number of bins with the `bins` kwarg\n",
    "# feature_counter = 0\n",
    "# for i in range(len(axs)):\n",
    "#     for j in range(len(axs[i])): \n",
    "#         current_feature = df_to_plot[features[feature_counter]]\n",
    "#         axs[i, j].hist(current_feature[df_to_plot['label']==0.0], n_bins, fc=(0, 1, 0, 0.5))\n",
    "#         axs[i, j].hist(current_feature[df_to_plot['label']==1.0], n_bins, fc=(1, 0, 0, 0.5))\n",
    "#         axs[i, j].set_title(f'Feature: {features[feature_counter]}')\n",
    "#         if features[feature_counter] == 'asdf':\n",
    "#             axs[i, j].set_ylim([0, current_feature.value_counts().iloc[0]]) \n",
    "#         else:\n",
    "#             axs[i, j].set_ylim([0, max(current_feature.value_counts())]) \n",
    "#         feature_counter += 1\n",
    "#     if feature_counter > len(features):\n",
    "#         break\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## Plotly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# js_array_len_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'content_mobnet_1'\n",
    "# feature = dataset_surt_norm.columns[2]\n",
    "dataset_to_plot = dataset_surtur_ext_feat\n",
    "\n",
    "good_filter = dataset_to_plot[feature][dataset_to_plot['label'] == 0]#.progress_apply(lambda x: roundup(x))\n",
    "bad_filter = dataset_to_plot[feature][dataset_to_plot['label'] == 1]#.progress_apply(lambda x: roundup(x))\n",
    "\n",
    "\n",
    "# bad_filter = bad_filter[bad_filter!=bad_filter.max()]\n",
    "\n",
    "trace1 = go.Histogram(\n",
    "    x=good_filter,\n",
    "    name='Benign',\n",
    "    yaxis='y2'\n",
    "\n",
    ")\n",
    "\n",
    "trace2 = go.Histogram(\n",
    "    x=bad_filter,\n",
    "    name='Malicious',\n",
    "    yaxis='y2'\n",
    ")\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(trace1)\n",
    "fig.add_trace(trace2,secondary_y=True)\n",
    "\n",
    "fig['layout'].update(height = 700, width = 1000, title = f'Feature: {feature}',xaxis=dict(tickangle=-90))\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_surtur_ext_feat.drop(columns = ['label', 'content', 'hostname', 'url', \n",
    "                                   'js', 'domain', 'google_is_safe', 'ip_address']).astype('float32')\n",
    "y = dataset_surtur['label']\n",
    "\n",
    "# X_new = SelectKBest(chi2, k=30).fit_transform(X, dataset_surtur['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_embedded_2D = TSNE(n_components = 2, random_state = 0, n_jobs=-1, init='pca').fit_transform(X)\n",
    "# X_embedded_3D = TSNE(n_components = 3, random_state = 0, n_jobs=-1, init='pca').fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_embedded_2D.to_csv('./2D_tsne_surtur.csv', index=False)\n",
    "# X_embedded_3D.to_csv('./3D_tsne_surtur.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z,\n",
    "#                                    mode='markers')])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgboost_model = XGBClassifier(verbosity=1, \n",
    "#                               max_depth=6,\n",
    "#                               n_estimators=100,\n",
    "#                               colsample_bylevel=1, \n",
    "#                               num_parallel_tree=1,\n",
    "#                               learning_rate=0.3,\n",
    "# #                               tree_method='approx', \n",
    "# #                               booster='dart',\n",
    "#                               n_jobs=-1)\n",
    "\n",
    "# xgboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier()\n",
    "\n",
    "xgboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['benign', 'malicious'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_imp = xgboost_model.feature_importances_\n",
    "feat_dict = {}\n",
    "\n",
    "for i in range(len(feat_imp)):\n",
    "    feat_dict[X.columns[i]] = feat_imp[i]\n",
    "    \n",
    "feat_dict = {k: v for k, v in sorted(feat_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "print(\"{:<25} {:<25}\".format('Feature' ,'Importance'))\n",
    "for k, v in feat_dict.items():\n",
    "    num = v\n",
    "    print(\"{:<25} {:<25}\".format(k, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1280*3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.drop(columns=['content_mobnet_0', 'content_mobnet_2', 'malicious_func_count', \n",
    "#                 'num_equals', 'total_url_count', 'domain_len', 'num_spaces', \n",
    "#                 'content_mobnet_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_misclassified = []\n",
    "for index, value in tqdm(enumerate(y_pred), total=len(y_pred)):\n",
    "    if value != y_test.values[index] and y_test.values[index]==1:\n",
    "        idx_misclassified.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.mean() - X_test.iloc[idx_misclassified].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_surtur.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rfc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, \n",
    "                            target_names=['benign', 'malicious'], \n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}\n",
    "\n",
    "svm_model = svm.SVC(verbose=3)\n",
    "clf = GridSearchCV(svm_model, param_grid, n_jobs=-1, cv=3, verbose=3)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, \n",
    "                            target_names=['benign', 'malicious'], \n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, AveragePooling2D, Flatten, Dropout\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "model = Sequential([\n",
    "#     Conv2D(filters=6,\n",
    "#            kernel_size=(3, 3),\n",
    "#            activation='relu',\n",
    "#            input_shape=X_train.shape),\n",
    "#     Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "#     AveragePooling2D(),\n",
    "#     Flatten(),\n",
    "    Dense(units=22210, activation='relu'),\n",
    "    Dense(units=11210, activation='relu'),\n",
    "    Dense(units=1841, activation='relu'),\n",
    "    Dense(units=1, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_history = model.fit(X_train, y_train, #validation_data=(X_valid_NN, y_valid_NN), \n",
    "                          epochs=5, batch_size=256, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "plt.subplots(figsize=(30,20))\n",
    "corrMatrix = X.corr()\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def histogram_intersection(a, b):\n",
    "#     v = np.minimum(a, b).sum().round(decimals=1)\n",
    "#     return v\n",
    "\n",
    "# X.corr(method=histogram_intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = SelectKBest(chi2, k=8).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['benign', 'malicious'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_selector(X, y, num_feats):\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature\n",
    "\n",
    "cor_support, cor_feature = cor_selector(X, y, 55)\n",
    "print(str(len(cor_feature)), 'selected features')\n",
    "print(' ')\n",
    "print(cor_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[cor_feature], y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, \n",
    "                            target_names=['benign', 'malicious'], \n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "836.75px",
    "left": "47px",
    "top": "136.283px",
    "width": "641.1px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
