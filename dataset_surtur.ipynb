{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Surtur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob as globlin\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urlextract import URLExtract\n",
    "import statistics\n",
    "import os\n",
    "import csv\n",
    "import onemillion\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import signal\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import plot, iplot\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timeout(time):\n",
    "    # Register a function to raise a TimeoutError on the signal.\n",
    "    signal.signal(signal.SIGALRM, raise_timeout)\n",
    "    # Schedule the signal to be sent after ``time``.\n",
    "    signal.alarm(time)\n",
    "\n",
    "    try:\n",
    "        yield\n",
    "    except TimeoutError:\n",
    "        return 'timeout error'\n",
    "    finally:\n",
    "        # Unregister the signal so it won't be triggered\n",
    "        # if the timeout is not reached.\n",
    "        signal.signal(signal.SIGALRM, signal.SIG_IGN)\n",
    "\n",
    "\n",
    "def raise_timeout(signum, frame):\n",
    "    raise TimeoutError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(main_path):\n",
    "    \"\"\"reading the benign samples\"\"\"\n",
    "    dataframe_array = []\n",
    "    benign_data_paths = globlin(main_path)\n",
    "    for path in benign_data_paths:\n",
    "        dataframe_array.append(pd.read_csv(path))\n",
    "        #print(pd.read_csv(path).columns)\n",
    "    return pd.concat(dataframe_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmadchaiban/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_surtur = read_data('./data_construction/4 - final_data/*.csv').drop(columns=['Unnamed: 0.1'])\n",
    "df_mal_sup = read_data('./data_construction/supp_malicious_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mal_sup = df_mal_sup.drop(columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur = dataset_surtur.drop(columns=['status', 'https.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mal_sup.columns = ['url', 'has_IP_in_url', 'number_subdomains', 'hostname',\n",
    "       'length_hostname', 'ratio_digits_url', 'having_@_in_url',\n",
    "       'ratio_digits_hostname', 'number_underscores', 'tld', 'url_len',\n",
    "       'https', 'who_is', 'content', 'label']\n",
    "\n",
    "df_mal_sup.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur = pd.concat([dataset_surtur, df_mal_sup], axis=0, sort=False).drop_duplicates()\n",
    "dataset_surtur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting JS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_js(content, supp=False):\n",
    "    tags_of_interest = [\n",
    "        '<script type=\"text/javascript\">', \n",
    "        '<script>'\n",
    "    ]\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    js = soup.find_all('script')\n",
    "    complete_js = ''\n",
    "    for tag in js:\n",
    "        for tag_int in tags_of_interest:\n",
    "            if tag_int in str(tag):\n",
    "                complete_js += str(tag).replace(tag_int, '').replace(\n",
    "                    '</script>', '')\n",
    "    return complete_js.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['js'] = dataset_surtur['content'].progress_apply(lambda content: get_js(str(content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JS Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['js_len'] = dataset_surtur['js'].progress_apply(lambda js: len(js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_string_thing = dataset_surtur[dataset_surtur['js_len']==0].iloc[1]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Script tag references in html page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def script_references(js):\n",
    "    return js.count('<script')/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['js_ref'] = dataset_surtur['content'].progress_apply(\n",
    "    lambda content: script_references(str(content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting array lengths from JS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_array_length(js):\n",
    "    array_lengths = re.findall('\\(([^\\)]+)\\)', js)\n",
    "    if array_lengths == []:\n",
    "        return 0\n",
    "    return max([len(i) for i in array_lengths])\n",
    "\n",
    "def get_avg_array_length(js):\n",
    "    array_lengths = re.findall('\\(([^\\)]+)\\)', js)\n",
    "    if array_lengths == []:\n",
    "        return 0\n",
    "    return statistics.mean([len(i) for i in array_lengths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['js_array_len_avg'] = dataset_surtur['js'].progress_apply(\n",
    "    lambda js: get_avg_array_length(str(js)))\n",
    "dataset_surtur['js_array_len_max'] = dataset_surtur['js'].progress_apply(\n",
    "    lambda js: get_max_array_length(str(js)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['content_len'] = dataset_surtur['content'].progress_apply(\n",
    "    lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['js'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_func_calls(js):\n",
    "    full_paren = len(re.findall(\"\\(([^\\)]+)\\)\", js))\n",
    "    empty_paren = len(js.split('()'))\n",
    "    return full_paren + empty_paren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['num_js_func_calls'] = dataset_surtur['js'].progress_apply(\n",
    "    lambda x: get_func_calls(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suspicious Function Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sus_js_function_count(js):\n",
    "    function_list = [\n",
    "        'setcookie', 'getcookie', 'createxmlhttprequest', 'unescape',\n",
    "        'document.write', 'element.appendchild', 'dateobject.togmtstring',\n",
    "        'new activexobject', 'document.createelement', 'getappname',\n",
    "        'getuseragent', 'window.setinterval', 'window.settimeout',\n",
    "        'location.assign', 'location.replace', 'eval()', 'string.indexof',\n",
    "        'string.fromcharcode', 'charat', 'split',\n",
    "        'string.charcodeat', 'document.writeln', 'document.appendchild',\n",
    "        'innerhtml', 'insertAdjacentHTML', 'outerhtml', \n",
    "    ]\n",
    "\n",
    "    split_js = js.replace('\\n',' ').split(' ')\n",
    "    counter = 0\n",
    "    for element in split_js:\n",
    "        if any(m_function in element.lower() for m_function in function_list):\n",
    "            counter += 1\n",
    "\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['malicious_func_count'] = dataset_surtur['js'].progress_apply(\n",
    "    lambda js: get_sus_js_function_count(str(js)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get total and external URL count in content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_urls(string, ext_count):\n",
    "#     # with timeout(1):\n",
    "#     regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "#     url = re.findall(regex, string)\n",
    "#     if ext_count:\n",
    "#         return len(set(url))\n",
    "#     return len(url)\n",
    "\n",
    "\n",
    "# # Test Code\n",
    "# string = 'My Profile: https://auth.geeksforgeeks.org/user/Chinmoy%20Lenka/articles in the portal of http://www.geeksforgeeks.org/'\n",
    "# print(\"Urls: \", find_urls(string, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_urls(string, ext_count):\n",
    "    try:\n",
    "        extractor = URLExtract()\n",
    "        urls = extractor.find_urls(string)\n",
    "        if ext_count: \n",
    "            return len(set(urls))\n",
    "        return len(urls)\n",
    "    except:\n",
    "        return 10000\n",
    "\n",
    "string_ex = 'My Profile: https://auth.geeksforgeeks.org/user/Chinmoy%20Lenka/articles in the portal of http://www.geeksforgeeks.org/'\n",
    "    \n",
    "print(find_urls(string_ex, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['total_url_count'] = dataset_surtur['content'].progress_apply(\n",
    "    lambda js: find_urls(str(js), False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['ext_url_count'] = dataset_surtur['content'].progress_apply(\n",
    "    lambda js: find_urls(str(js), True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Lexical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['num_semicolons'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count(';'))\n",
    "dataset_surtur['num_zeros'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('0'))\n",
    "dataset_surtur['num_spaces'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('%20'))\n",
    "dataset_surtur['num_hyphens'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('-'))\n",
    "dataset_surtur['num_@s'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('@'))\n",
    "dataset_surtur['num_queries'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('?'))\n",
    "dataset_surtur['num_ampersands'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('&'))\n",
    "dataset_surtur['num_equals'] = dataset_surtur['url'].progress_apply(lambda url: str(url).count('='))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safe Browsing API Judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./safebrowsingkey.txt') as f:\n",
    "    api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/105492 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 30556/105492 [2:09:00<9:30:34,  2.19it/s] "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "key = 'your key here'\n",
    "URL = \"https://sb-ssl.google.com/safebrowsing/api/lookup?client=api&apikey={key}&appver=1.0&pver=3.0&url={url}\"\n",
    "\n",
    "\n",
    "def is_safe(url):\n",
    "    try:\n",
    "        response = requests.get(URL.format(key=api_key, url=url))\n",
    "        return response.text != 'malware'\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "\n",
    "print(is_safe('http://addonrock.ru/Debugger.js/'))  # prints False\n",
    "print(is_safe('http://google.com'))  # prints True\n",
    "\n",
    "\n",
    "dataset_surtur['google_is_safe'] = dataset_surtur['url'].progress_apply(lambda url: is_safe(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Domain names and their lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['domain'] = dataset_surtur['hostname'].progress_apply(\n",
    "    lambda hostname: '.'.join(str(hostname).split('.')[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['domain_len'] = dataset_surtur['domain'].progress_apply(lambda domain: len(domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presence in Alexa domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'domain_lists': [\n",
    "        {\n",
    "            'name': \"alexa\",\n",
    "            'output_file_path': \"alexa.csv\",\n",
    "            'url': \"http://s3.amazonaws.com/alexa-static/top-1m.csv.zip\"\n",
    "        }, {\n",
    "            'name': \"cisco umbrella\",\n",
    "            'output_file_path': \"cisco.csv\",\n",
    "            'url': \"http://s3-us-west-1.amazonaws.com/umbrella-static/\" +\n",
    "                   \"top-1m.csv.zip\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Cache our top 1 million known domains\n",
    "DEFAULT_CACHE_LOCATION = '~/.onemillion'\n",
    "cache_location = os.path.expanduser(DEFAULT_CACHE_LOCATION)\n",
    "\n",
    "# O(n) to read Csv file rows into set \n",
    "def read_onemillion_data():\n",
    "    \"\"\"Check if the given domain is in a top on million list.\"\"\"\n",
    "    # TODO: parse the registered domain out of the domain parameter\n",
    "\n",
    "    # keep track of the highest (nearest to 1) rank for the given domain\n",
    "    highest_rank = None\n",
    "\n",
    "    # see if the given domain is in the up-to-date domain lists\n",
    "    domains = set()\n",
    "    for domain_list in CONFIG['domain_lists']:\n",
    "        # open the domain list as a CSV\n",
    "        with open(os.path.join(cache_location, domain_list['output_file_path']), 'r') as domain_csv:\n",
    "            domain_reader = csv.reader(domain_csv)\n",
    "            for row in domain_reader:\n",
    "                domains.add(row[1])\n",
    "    return domains\n",
    "\n",
    "\n",
    "domains_onemillion = read_onemillion_data()\n",
    "\n",
    "# O(1) Function Run time\n",
    "def domain_checker(domain):\n",
    "    domain = domain.lower()\n",
    "    if domain in domains:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "o = onemillion.OneMillion()\n",
    "\n",
    "def check_if_in_onemillion(domain):\n",
    "    if domain in domains_onemillion:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "dataset_surtur['is_in_alexa'] = dataset_surtur['domain'].progress_apply(\n",
    "    lambda domain: check_if_in_onemillion(domain))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_adjustor(dataset_column):\n",
    "    unique_values = dataset_column.unique()\n",
    "    return dataset_column.progress_apply(lambda x: np.where(unique_values == x)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur = dataset_surtur.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['who_is'] = column_adjustor(dataset_surtur['who_is'])\n",
    "dataset_surtur['https'] = column_adjustor(dataset_surtur['https'])\n",
    "dataset_surtur['tld'] = column_adjustor(dataset_surtur['tld'])\n",
    "\n",
    "dataset_surtur['label'] = dataset_surtur['label'].progress_apply(\n",
    "    lambda label: 1 if 'bad' in label else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_surtur.to_csv('./dataset_surtur.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>has_IP_in_url</th>\n",
       "      <th>having_@_in_url</th>\n",
       "      <th>hostname</th>\n",
       "      <th>https</th>\n",
       "      <th>label</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>number_subdomains</th>\n",
       "      <th>number_underscores</th>\n",
       "      <th>ratio_digits_hostname</th>\n",
       "      <th>ratio_digits_url</th>\n",
       "      <th>tld</th>\n",
       "      <th>url</th>\n",
       "      <th>url_len</th>\n",
       "      <th>who_is</th>\n",
       "      <th>js</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_ref</th>\n",
       "      <th>js_array_len_avg</th>\n",
       "      <th>js_array_len_max</th>\n",
       "      <th>content_len</th>\n",
       "      <th>num_js_func_calls</th>\n",
       "      <th>malicious_func_count</th>\n",
       "      <th>total_url_count</th>\n",
       "      <th>ext_url_count</th>\n",
       "      <th>num_semicolons</th>\n",
       "      <th>num_zeros</th>\n",
       "      <th>num_spaces</th>\n",
       "      <th>num_hyphens</th>\n",
       "      <th>num_@s</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>num_ampersands</th>\n",
       "      <th>num_equals</th>\n",
       "      <th>domain</th>\n",
       "      <th>domain_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;!DOCT...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>islandvolleyballclub.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://islandvolleyballclub.com/venues.html</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b''</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7813</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>islandvolleyballclub.com</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.indiosoftware.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.indiosoftware.com/</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'\\nfunction getCookie(c_name) { // Local func...</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>69</td>\n",
       "      <td>1556</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>indiosoftware.com</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;html&gt;\\n&lt;head&gt;\\n&lt;meta content=\"text/html; char...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>naturalfilters.bizland.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://naturalfilters.bizland.com/aquarain/</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'\\nfunction myopen(filename,windowname,proper...</td>\n",
       "      <td>133</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30</td>\n",
       "      <td>26533</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bizland.com</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\n\\n&lt;html&gt;&lt;!-- InstanceBegin te...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.rosepath.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.rosepath.com</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'qm_create(0,false,0,0,false,false,false,fals...</td>\n",
       "      <td>53</td>\n",
       "      <td>1.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41</td>\n",
       "      <td>6465</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rosepath.com</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>could not fetch content</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.plannedparrothood.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.plannedparrothood.com/</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>b''</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>plannedparrothood.com</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  has_IP_in_url  \\\n",
       "0  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCT...            0.0   \n",
       "1  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//...            0.0   \n",
       "2  <html>\\n<head>\\n<meta content=\"text/html; char...            0.0   \n",
       "3  <!DOCTYPE HTML>\\n\\n<html><!-- InstanceBegin te...            0.0   \n",
       "4                            could not fetch content            0.0   \n",
       "\n",
       "   having_@_in_url                    hostname  https  label  length_hostname  \\\n",
       "0              0.0    islandvolleyballclub.com      0      0             24.0   \n",
       "1              0.0       www.indiosoftware.com      0      0             21.0   \n",
       "2              0.0  naturalfilters.bizland.com      0      0             26.0   \n",
       "3              0.0            www.rosepath.com      0      0             16.0   \n",
       "4              0.0   www.plannedparrothood.com      0      0             25.0   \n",
       "\n",
       "   number_subdomains  number_underscores  ratio_digits_hostname  \\\n",
       "0                0.0                 0.0                    0.0   \n",
       "1                1.0                 0.0                    0.0   \n",
       "2                1.0                 0.0                    0.0   \n",
       "3                1.0                 0.0                    0.0   \n",
       "4                1.0                 0.0                    0.0   \n",
       "\n",
       "   ratio_digits_url  tld                                          url  \\\n",
       "0               0.0    0  http://islandvolleyballclub.com/venues.html   \n",
       "1               0.0    0                http://www.indiosoftware.com/   \n",
       "2               0.0    0  http://naturalfilters.bizland.com/aquarain/   \n",
       "3               0.0    0                      http://www.rosepath.com   \n",
       "4               0.0    0            http://www.plannedparrothood.com/   \n",
       "\n",
       "   url_len  who_is                                                 js  js_len  \\\n",
       "0     43.0       0                                                b''       0   \n",
       "1     29.0       0  b'\\nfunction getCookie(c_name) { // Local func...    1103   \n",
       "2     43.0       0  b'\\nfunction myopen(filename,windowname,proper...     133   \n",
       "3     23.0       0  b'qm_create(0,false,0,0,false,false,false,fals...      53   \n",
       "4     33.0       0                                                b''       0   \n",
       "\n",
       "   js_ref  js_array_len_avg  js_array_len_max  content_len  num_js_func_calls  \\\n",
       "0     0.0               0.0                 0         7813                  1   \n",
       "1     0.5              17.2                69         1556                 23   \n",
       "2     0.5              30.0                30        26533                  4   \n",
       "3     1.5              41.0                41         6465                  2   \n",
       "4     0.0               0.0                 0           23                  1   \n",
       "\n",
       "   malicious_func_count  total_url_count  ext_url_count  num_semicolons  \\\n",
       "0                     0               15             14               0   \n",
       "1                     4                2              2               0   \n",
       "2                     0               40             28               0   \n",
       "3                     0                5              5               0   \n",
       "4                     0                0              0               0   \n",
       "\n",
       "   num_zeros  num_spaces  num_hyphens  num_@s  num_queries  num_ampersands  \\\n",
       "0          0           0            0       0            0               0   \n",
       "1          0           0            0       0            0               0   \n",
       "2          0           0            0       0            0               0   \n",
       "3          0           0            0       0            0               0   \n",
       "4          0           0            0       0            0               0   \n",
       "\n",
       "   num_equals                    domain  domain_len  \n",
       "0           0  islandvolleyballclub.com          24  \n",
       "1           0         indiosoftware.com          17  \n",
       "2           0               bizland.com          11  \n",
       "3           0              rosepath.com          12  \n",
       "4           0     plannedparrothood.com          21  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_surtur = pd.read_csv('./dataset_surtur.csv')\n",
    "dataset_surtur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_surtur = dataset_surtur[dataset_surtur['content']!='could not fetch content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    61083\n",
       "1    44409\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_surtur['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = dataset_surtur.drop(\n",
    "    columns=['url', 'content', 'hostname', 'js', 'label']).columns[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = dataset_surtur.drop(\n",
    "    columns=['url', 'content', 'hostname', 'js', 'label', 'domain']).columns[::-1]\n",
    "# 'total_url_count', 'ext_url_count'\n",
    "\n",
    "x = dataset_surtur[dataset_surtur['label'] == 1][to_keep].copy()  #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x.values)\n",
    "df_to_plot_malicious = pd.DataFrame(x_scaled)\n",
    "df_to_plot_malicious.columns = dataset_surtur[to_keep].columns\n",
    "df_to_plot_malicious['label'] = 1.0\n",
    "\n",
    "x = dataset_surtur[dataset_surtur['label'] == 0][to_keep].copy()  #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x.values)\n",
    "df_to_plot_benign = pd.DataFrame(x_scaled)\n",
    "df_to_plot_benign.columns = dataset_surtur[to_keep].columns\n",
    "df_to_plot_benign['label'] = 0.0\n",
    "\n",
    "normalized_per_class_dataset = pd.concat([df_to_plot_malicious, df_to_plot_benign], axis=0)\n",
    "\n",
    "x = dataset_surtur[to_keep].copy()  #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x.values)\n",
    "dataset_surt_norm = pd.DataFrame(x_scaled)\n",
    "dataset_surt_norm.columns = dataset_surtur[to_keep].columns\n",
    "dataset_surt_norm['label'] = dataset_surtur['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "\n",
    "# num_df_surt = dataset_surt_norm.select_dtypes(include=[\"number\"])\n",
    "# cat_df_surt = dataset_surt_norm.select_dtypes(exclude=[\"number\"])\n",
    "\n",
    "# # idx = np.all(stats.zscore(num_df_surt) < 3, axis=1)\n",
    "\n",
    "# # dataset_surt_norm_cleaned = pd.concat([num_df_surt.loc[idx], \n",
    "# #                                    cat_df_surt.loc[idx]], axis=1)\n",
    "\n",
    "# Q1 = num_df_surt.quantile(0.10)\n",
    "# Q3 = num_df_surt.quantile(0.80)\n",
    "# IQR = Q3 - Q1\n",
    "# idx = ~((num_df_surt < (Q1 - 1.5 * IQR)) | (num_df_surt > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "# dataset_surt_norm_cleaned = pd.concat([num_df_surt.loc[idx], \n",
    "#                                     cat_df_surt.loc[idx]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataset_surt_norm_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes_to_drop = dataset_surtur.nlargest(15000, 'js_len')['js_len'].index\n",
    "# dataset_surtur = dataset_surtur.drop(indexes_to_drop, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = dataset_surtur.drop(columns=['url', 'content', 'hostname', 'js', \n",
    "                                        'label']).columns[::-1] #, 'total_url_count', 'ext_url_count']).columns[::-1]\n",
    "df_to_plot = dataset_surtur\n",
    "\n",
    "n_bins = 40\n",
    "\n",
    "fig, axs = plt.subplots(3, 6, figsize=(20,20))\n",
    "\n",
    "# We can set the number of bins with the `bins` kwarg\n",
    "feature_counter = 0\n",
    "for i in range(len(axs)):\n",
    "    for j in range(len(axs[i])): \n",
    "        current_feature = df_to_plot[features[feature_counter]]\n",
    "        axs[i, j].hist(current_feature[df_to_plot['label']==0.0], n_bins, fc=(0, 1, 0, 0.5))\n",
    "        axs[i, j].hist(current_feature[df_to_plot['label']==1.0], n_bins, fc=(1, 0, 0, 0.5))\n",
    "        axs[i, j].set_title(f'Feature: {features[feature_counter]}')\n",
    "        if features[feature_counter] == 'asdf':\n",
    "            axs[i, j].set_ylim([0, current_feature.value_counts().iloc[0]]) \n",
    "        else:\n",
    "            axs[i, j].set_ylim([0, max(current_feature.value_counts())]) \n",
    "        feature_counter += 1\n",
    "    if feature_counter > 14:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## Plotly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# js_array_len_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'is_in_alexa'\n",
    "# feature = dataset_surt_norm.columns[2]\n",
    "dataset_to_plot = dataset_surtur\n",
    "\n",
    "good_filter = dataset_to_plot[feature][dataset_to_plot['label'] == 0]#.progress_apply(lambda x: roundup(x))\n",
    "bad_filter = dataset_to_plot[feature][dataset_to_plot['label'] == 1]#.progress_apply(lambda x: roundup(x))\n",
    "\n",
    "\n",
    "# bad_filter = bad_filter[bad_filter!=bad_filter.max()]\n",
    "\n",
    "trace1 = go.Histogram(\n",
    "    x=good_filter,\n",
    "    name='Benign',\n",
    "    yaxis='y2'\n",
    "\n",
    ")\n",
    "\n",
    "trace2 = go.Histogram(\n",
    "    x=bad_filter,\n",
    "    name='Malicious',\n",
    "    yaxis='y2'\n",
    ")\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(trace1)\n",
    "fig.add_trace(trace2,secondary_y=True)\n",
    "\n",
    "fig['layout'].update(height = 700, width = 1000, title = f'Feature: {feature}',xaxis=dict(tickangle=-90))\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_surtur.drop(columns = ['label', 'content', 'hostname', 'url', \n",
    "                                   'js', 'domain']).astype('float32') # 'total_url_count', 'ext_url_count'\n",
    "# X = np.array(X).reshape([len(X), 1])\n",
    "y = dataset_surtur['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['benign', 'malicious'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.iloc[29664]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, prediction in enumerate(y_pred):\n",
    "    if prediction != y_test.values[index] and y_test.values[index] == 1:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, value in enumerate(y_pred):\n",
    "#     if value != y_test[index]:\n",
    "#         pass\n",
    "#         #print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surtur.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rfc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, \n",
    "                            target_names=['benign', 'malicious'], \n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}\n",
    "\n",
    "svm_model = svm.SVC(verbose=3)\n",
    "clf = GridSearchCV(svm_model, param_grid, n_jobs=-1, cv=3, verbose=3)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, \n",
    "                            target_names=['benign', 'malicious'], \n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, AveragePooling2D, Flatten, Dropout\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "model = Sequential([\n",
    "#     Conv2D(filters=6,\n",
    "#            kernel_size=(3, 3),\n",
    "#            activation='relu',\n",
    "#            input_shape=X_train.shape),\n",
    "#     Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "#     AveragePooling2D(),\n",
    "#     Flatten(),\n",
    "    Dense(units=1210, activation='relu'),\n",
    "    Dense(units=841, activation='relu'),\n",
    "    Dense(units=1, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_history = model.fit(X_train, y_train, #validation_data=(X_valid_NN, y_valid_NN), \n",
    "                          epochs=5, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "plt.subplots(figsize=(30,20))\n",
    "corrMatrix = X.corr()\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_intersection(a, b):\n",
    "    v = np.minimum(a, b).sum().round(decimals=1)\n",
    "    return v\n",
    "\n",
    "X.corr(method=histogram_intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = SelectKBest(chi2, k=8).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['benign', 'malicious'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "48.25px",
    "left": "86px",
    "top": "214.2px",
    "width": "159.867px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
